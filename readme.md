# üöÄ Workflow de Desenvolvimento - Spark Manual

## üìã Vis√£o Geral

Este guia mostra como usar o ambiente onde:
- **Kafka + Zookeeper + Producer** ficam rodando continuamente
- **Spark** voc√™ executa manualmente quando quiser testar seu c√≥digo

## üèóÔ∏è Configura√ß√£o Inicial

### 1. Subir apenas a infraestrutura (Kafka + Producer)

```bash
# Inicia Kafka, Zookeeper, Producer e container Spark (mas n√£o executa o c√≥digo)
docker-compose up -d --build

# Verificar se est√° tudo rodando
docker-compose ps
```

Voc√™ ver√°:
```
NAME              STATUS          PORTS
kafka             Up (healthy)    0.0.0.0:9092->9092/tcp
python-producer   Up              
spark-dev         Up              0.0.0.0:4040->4040/tcp
zookeeper         Up              0.0.0.0:2181->2181/tcp
```

## üî• Executando o Spark Manualmente

### ‚ö†Ô∏è IMPORTANTE: Escolha o Terminal Correto no Windows

**Windows**: Use **PowerShell** ou **CMD** (N√ÉO use Git Bash)
- Git Bash converte caminhos incorretamente e causar√° erro

### Op√ß√£o 1: Executar o consumer.py (comando √∫nico)

```powershell
# Windows PowerShell (RECOMENDADO)
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# Windows CMD
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# Git Bash (se realmente precisar usar)
MSYS_NO_PATHCONV=1 docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# Linux/Mac
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py
```

### Op√ß√£o 2: Entrar no container e executar (mais flex√≠vel)

```bash
# Entra no container
docker exec -it spark-dev bash

# Dentro do container, execute:
spark-submit --master local[*] /app/consumer.py

# Ou com mais op√ß√µes:
spark-submit \
  --master local[*] \
  --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint \
  /app/consumer.py

# Para sair do container
exit
```

### Op√ß√£o 3: Executar com Python direto (para testes r√°pidos)

```bash
docker exec -it spark-dev python /app/consumer.py
```

## üìù Workflow de Desenvolvimento Di√°rio

### 1Ô∏è‚É£ Manh√£ - Iniciar o ambiente

```bash
# Sobe toda a infraestrutura
docker-compose up -d --build

# Verifica logs do producer (opcional)
docker-compose logs -f python-producer
```

### 2Ô∏è‚É£ Durante o dia - Desenvolver e testar

```powershell
# IMPORTANTE: Use PowerShell ou CMD no Windows (n√£o Git Bash)

# 1. Edite o arquivo spark-consumer/consumer.py no seu editor favorito (VS Code, PyCharm, etc.)

# 2. Teste suas altera√ß√µes (PowerShell/CMD)
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# 3. Se der erro, CTRL+C e ajuste o c√≥digo

# 4. Execute novamente (n√£o precisa rebuild!)
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py
```

### 3Ô∏è‚É£ Fim do dia - Parar tudo

```bash
# Para todos os containers
docker-compose down

# Ou se quiser manter os dados do Kafka:
docker-compose stop
```

## üéØ Comandos √öteis

### Ver logs em tempo real

```bash
# Todos os servi√ßos
docker-compose logs -f

# Apenas o producer
docker-compose logs -f python-producer

# Apenas o Kafka
docker-compose logs -f kafka
```

### Ver t√≥picos do Kafka

```bash
# Lista os t√≥picos
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# Descreve um t√≥pico
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ordem
```

### Consumir mensagens do Kafka manualmente

```bash
# Ver mensagens do t√≥pico 'ordem'
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ordem \
  --from-beginning \
  --max-messages 5

# Ver mensagens do t√≥pico 'eventos'
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic eventos \
  --from-beginning \
  --max-messages 5
```

### Limpar checkpoint do Spark (se necess√°rio)

```bash
docker exec -it spark-dev rm -rf /tmp/checkpoint
```

### Acessar Spark UI

Quando o Spark estiver rodando, acesse:
```
http://localhost:4040
```

## üîß Testando Diferentes Configura√ß√µes do Spark

### Com mais mem√≥ria

```bash
docker exec -it spark-dev spark-submit \
  --master local[*] \
  --driver-memory 2g \
  --executor-memory 2g \
  /app/consumer.py
```

### Com mais cores

```bash
docker exec -it spark-dev spark-submit \
  --master local[4] \
  /app/consumer.py
```

### Com configura√ß√µes customizadas

```bash
docker exec -it spark-dev spark-submit \
  --master local[*] \
  --conf spark.sql.shuffle.partitions=4 \
  --conf spark.streaming.stopGracefullyOnShutdown=true \
  /app/consumer.py
```

## üêõ Troubleshooting

### Spark n√£o conecta ao Kafka
```bash
# Verifica se o Kafka est√° rodando
docker-compose ps kafka

# Verifica logs do Kafka
docker-compose logs kafka
```

### C√≥digo n√£o atualiza
```bash
# As mudan√ßas s√£o autom√°ticas porque usamos volumes!
# Apenas execute novamente:
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py
```

### Quer reconstruir o container Spark
```bash
# Se mudou o Dockerfile ou requirements.txt:
docker-compose up -d --build spark-dev
```

## üí° Dicas Pro

### ‚ö†Ô∏è Problema com Git Bash no Windows

O Git Bash converte caminhos Linux automaticamente, causando erros como:
```
python3: can't open file '/app/C:/Program Files/Git/app/consumer.py'
```

**Solu√ß√µes:**
1. **Use PowerShell ou CMD** (recomendado)
2. No Git Bash, adicione `MSYS_NO_PATHCONV=1` antes do comando
3. No Git Bash, use `//app` ao inv√©s de `/app`

### Criar aliases no seu terminal

**Windows PowerShell** - Adicione no seu `$PROFILE`:
```powershell
# Para criar/editar o profile:
# notepad $PROFILE

function Run-SparkJob { docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py }
function Spark-Shell { docker exec -it spark-dev bash }
function Kafka-Logs { docker-compose logs -f python-producer }

Set-Alias spark-run Run-SparkJob
Set-Alias spark-shell Spark-Shell
Set-Alias kafka-logs Kafka-Logs
```

**Linux/Mac** - Adicione no `.bashrc` ou `.zshrc`:
```bash
alias spark-run="docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py"
alias spark-shell="docker exec -it spark-dev bash"
alias kafka-logs="docker-compose logs -f python-producer"
```

Depois voc√™ pode simplesmente digitar:
```bash
spark-run    # Executa o job
spark-shell  # Entra no container
kafka-logs   # Ver logs do producer
```

## üìä Exemplo de Sess√£o Completa

```powershell
# NOTA: Use PowerShell ou CMD no Windows

# 1. Sobe o ambiente
docker-compose up -d --build

# 2. Verifica se est√° tudo ok
docker-compose ps

# 3. Ver mensagens sendo produzidas
docker-compose logs -f python-producer

# 4. Em outro terminal PowerShell/CMD, executa o Spark
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# 5. Acessa Spark UI no navegador
# http://localhost:4040

# 6. Para parar o Spark: CTRL+C

# 7. Edita o c√≥digo no VS Code
# code spark-consumer/consumer.py

# 8. Executa novamente
docker exec -it spark-dev spark-submit --master local[*] /app/consumer.py

# 9. Ao final do dia
docker-compose down
```

## üéì Compara√ß√£o: Autom√°tico vs Manual

| Aspecto | Modo Autom√°tico | Modo Manual (Atual) |
|---------|----------------|---------------------|
| **Iniciar Spark** | Autom√°tico ao subir | Voc√™ controla quando executar |
| **Testar mudan√ßas** | Precisa rebuild | Instant√¢neo (apenas execute novamente) |
| **Desenvolvimento** | Mais lento | Mais r√°pido e flex√≠vel |
| **Produ√ß√£o** | ‚úÖ Ideal | ‚ùå N√£o recomendado |
| **Aprendizado** | Menos controle | ‚úÖ Mais controle e entendimento |

---

**‚ú® Vantagens deste workflow:**
- ‚ö° Testa mudan√ßas instantaneamente
- üéØ Controle total sobre quando executar
- üîß F√°cil debugar e experimentar
- üìö Melhor para aprendizado